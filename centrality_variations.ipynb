{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Centrality Variation Analysis\n",
    "\n",
    "This code performs centrality analysis on a network by comparing the baseline centrality values to the centrality values obtained after perturbing the network by removing each node individually. The analysis is performed using the Python programming language and various data analysis libraries such as Pandas and NumPy.\n",
    "\n",
    "## Functionality\n",
    "\n",
    "1. The code loads centrality data from a pickle file containing the baseline centrality values and perturbed centrality values.\n",
    "2. It concatenates the baseline and perturbed centrality data into a single DataFrame with a multi-index.\n",
    "3. The code defines a function to calculate the log2 ratio of baseline centrality to perturbed centrality for a given reaction.\n",
    "4. Another function applies the log2 ratio calculation to all reactions in the dataset and consolidates the results into a single DataFrame.\n",
    "5. The resulting centrality variations are saved as a compressed parquet file.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Ensure that you have the necessary dependencies installed (Pandas, NumPy).\n",
    "2. Modify the code to specify the correct file path for the input pickle file.\n",
    "3. Run the code in a Python environment or a Jupyter notebook.\n",
    "4. The output will be a parquet file containing the log2 ratio centrality variations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def load_data(file_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Loads data from a pickle file\"\"\"\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    return data['centralidades_perturbadas'], data['baseline']\n",
    "\n",
    "def concat_centralities(baseline: pd.DataFrame, centralidades_perturbadas: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Concatenates baseline and perturbed centralities\"\"\"\n",
    "    all_centralities = [baseline]\n",
    "    index_keys = [\"baseline\"]\n",
    "    for node in centralidades_perturbadas:\n",
    "        perturbed_centralities = node[1]\n",
    "        removed_node_name = node[0]\n",
    "        all_centralities.append(perturbed_centralities)\n",
    "        index_keys.append(removed_node_name)\n",
    "\n",
    "    centralidades_df = pd.concat(all_centralities, axis=0, keys=index_keys, names=[\"removed_node\", \"metabolite\"])\n",
    "    centralidades_df.sort_index(inplace=True)\n",
    "\n",
    "    return centralidades_df\n",
    "\n",
    "def log2RatioCentrality(baseline: pd.DataFrame, centralidades_df: pd.DataFrame, a_rxn: str) -> pd.DataFrame:\n",
    "    \"\"\"Computes log2 ratio of baseline centralities to the centralities of a given reaction\"\"\"\n",
    "    assert all(baseline.index.values == centralidades_df.loc[a_rxn].index.values), \"Index mismatch\"\n",
    "    return np.log2(baseline / centralidades_df.loc[a_rxn])\n",
    "\n",
    "def get_centrality_variation(variation_function, rxns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Applies the variation function to a list of reactions and consolidates the results into a single DataFrame\"\"\"\n",
    "    if \"baseline\" in rxns:\n",
    "        rxns.remove(\"baseline\")\n",
    "\n",
    "    my_iter = map(variation_function, rxns)\n",
    "    Centralities_list = []\n",
    "    for i_df, rxn in zip(my_iter, rxns):\n",
    "        i_df[\"removed_rxn\"] = rxn\n",
    "        i_df.reset_index(inplace=True)\n",
    "        i_df.set_index([\"removed_rxn\", \"metabolite\"], inplace=True)\n",
    "        Centralities_list.append(i_df)\n",
    "\n",
    "    return pd.concat(Centralities_list, axis=0)\n",
    "\n",
    "\n",
    "centralidades_perturbadas, baseline = load_data('aws-downloads/centralities.pickle')\n",
    "print(f\"Read centralidades_perturbadas of length: {len(centralidades_perturbadas)}\")\n",
    "print(f\"Read baseline of length: {len(baseline)}\")\n",
    "\n",
    "centralidades_df = concat_centralities(baseline, centralidades_perturbadas)\n",
    "baseline = centralidades_df.loc[\"baseline\"]\n",
    "\n",
    "all_rxns = list(np.unique(centralidades_df.index.get_level_values(\"removed_node\").values))\n",
    "log2Ratio_df = get_centrality_variation(lambda rxn: log2RatioCentrality(baseline, centralidades_df, rxn), all_rxns)\n",
    "log2Ratio_df.to_parquet(\"log2Ratio_df.parquet.gzip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
